\documentclass[a4paper,12pt,leqno]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
%                                     TODO                                     %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
% - Double check gutter margin is included                                     %
% - Make sure title page wording and formatting is acceptable                  %
%   - Should supervisors be included on title page?                            %
% - Does GDPR need to be included in Declaration?                              %
% - Make sure ADAPT acknowledgement is correct                                 %
% - Check all references are accurate and not abbreviated                      %
% - Find out if "Summary" should be included versus Abstract                   %
% - Include lists of tables/figures(?) and double-check for correct labels     %
% - Ensure 100k word limit is not reached... lol                               %
% - Check that appendices and other sections not automatically included in the %
%   TOC are accurate and up to date.                                           %
% * Should Related Publications be included?                                   %
% - Is Times a preferred font/does it matter?                                  %
% * Don't have solitary sections (e.g. 4.1.1 without 4.1.2)                    %
% - Vinny Wade and Dave Lewis may be internal examiners, so try to address the %
%   issues they brought up during the transfer                                 %
% - Should FST discussion bother talking about FS automata/transducers?        %
% - Remind examiners regularly of core concepts, don't expect them to remember %
% - Should lit review cover smaller topics eg scheduling or just major themes? %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Use I_A as correction to below for intervals, not nominals
% Use N_A for first order nominals, as first order ensures each element occurs exactly once, rather than L_A which allows infinite strings for the gap calculation thing

\usepackage{natbib}
%\usepackage{times}
\usepackage{url}
\usepackage{array}
\usepackage{latexsym}
\usepackage{caption}
\usepackage{amssymb,amsmath,amscd}
\usepackage{stmaryrd}
\usepackage{xcolor}
\usepackage[hang,flushmargin]{footmisc}
\usepackage{graphicx}  %%% for including graphics
%\usepackage[bindingoffset=10mm,margin=25mm]{geometry} % I think this is the required "gutter margin"
\usepackage[margin=25mm]{geometry}
\usepackage{setspace}
\usepackage{diagbox}
\usepackage[nodayofweek]{datetime}

\captionsetup[figure]{font=small,labelfont=small}

\def\drs#1#2{
\begin{tabular}[c]{| c |}
	\hline #1 \\
	\hline #2 \\
	\hline
\end{tabular}
}

% Tim's custom commands
\newcommand{\bc}{{\rm b\!c}}
\newcommand{\unpad}{\mbox{{\rm unpad}}}
\newcommand{\vph}[1]{\vphantom{#1}}
\newcommand{\sta}[2]{\stackrel{#1}{#2}}


% David's custom commands
\newcommand{\ebox}[1]{\fbox{$\vph{'(),}#1$}}
\newcommand{\eboxl}[1]{\fbox{$\vph{'}#1$}}
\newcommand{\eboxh}[1]{\fbox{$\vph{,}#1$}}
\newcommand{\eboxb}[1]{\fbox{$\vph{@}#1$}}

\newcommand{\nbBefore}[2]{\ebox{#1}\ebox{}\ebox{#2}}
\newcommand{\nbMeets}[2]{\ebox{#1}\ebox{#2}}
\newcommand{\nbOverlaps}[2]{\ebox{#1}\ebox{#1,#2}\ebox{#2}}
\newcommand{\nbDuring}[2]{\ebox{#2}\ebox{#1,#2}\ebox{#2}}
\newcommand{\nbStarts}[2]{\ebox{#1,#2}\ebox{#2}}
\newcommand{\nbFinishes}[2]{\ebox{#2}\ebox{#1,#2}}
\newcommand{\nbEquals}[2]{\ebox{#1,#2}}

\newcommand{\nbAfter}[2]{\nbBefore{#2}{#1}}
\newcommand{\nbiMeets}[2]{\nbMeets{#2}{#1}}
\newcommand{\nbiOverlaps}[2]{\nbOverlaps{#2}{#1}}
\newcommand{\nbiDuring}[2]{\nbDuring{#2}{#1}}
\newcommand{\nbiStarts}[2]{\nbStarts{#2}{#1}}
\newcommand{\nbiFinishes}[2]{\nbFinishes{#2}{#1}}

\newcommand{\Before}[2]{\ebox{}\nbBefore{#1}{#2}\ebox{}}
\newcommand{\Meets}[2]{\ebox{}\nbMeets{#1}{#2}\ebox{}}
\newcommand{\Overlaps}[2]{\ebox{}\nbOverlaps{#1}{#2}\ebox{}}
\newcommand{\During}[2]{\ebox{}\nbDuring{#1}{#2}\ebox{}}
\newcommand{\Starts}[2]{\ebox{}\nbStarts{#1}{#2}\ebox{}}
\newcommand{\Finishes}[2]{\ebox{}\nbFinishes{#1}{#2}\ebox{}}
\newcommand{\Equals}[2]{\ebox{}\nbEquals{#1}{#2}\ebox{}}
\newcommand{\After}[2]{\ebox{}\nbAfter{#1}{#2}\ebox{}}
\newcommand{\iMeets}[2]{\ebox{}\nbiMeets{#1}{#2}\ebox{}}
\newcommand{\iOverlaps}[2]{\ebox{}\nbiOverlaps{#1}{#2}\ebox{}}
\newcommand{\iDuring}[2]{\ebox{}\nbiDuring{#1}{#2}\ebox{}}
\newcommand{\iStarts}[2]{\ebox{}\nbiStarts{#1}{#2}\ebox{}}
\newcommand{\iFinishes}[2]{\ebox{}\nbiFinishes{#1}{#2}\ebox{}}

\newcommand{\cBefore}[2]{``$#1$  before $#2$'' -- \Before{#1}{#2}}
\newcommand{\cMeets}[2]{``$#1$ meets $#2$'' -- \Meets{#1}{#2}}
\newcommand{\cOverlaps}[2]{``$#1$ overlaps $#2$'' -- \Overlaps{#1}{#2}}
\newcommand{\cDuring}[2]{``$#1$ during $#2$'' -- \During{#1}{#2}}
\newcommand{\cStarts}[2]{``$#1$ starts $#2$'' -- \Starts{#1}{#2}}
\newcommand{\cFinishes}[2]{``$#1$ finishes $#2$'' -- \Finishes{#1}{#2}}
\newcommand{\cEquals}[2]{``$#1$ equals $#2$'' -- \Equals{#1}{#2}}
\newcommand{\cAfter}[2]{``$#1$ after $#2$'' -- \After{#1}{#2}}
\newcommand{\ciMeets}[2]{``$#1$ imet by $#2$'' -- \iMeets{#1}{#2}}
\newcommand{\ciOverlaps}[2]{``$#1$ overlapped by $#2$'' -- \iOverlaps{#1}{#2}}
\newcommand{\ciDuring}[2]{``$#1$ contains $#2$'' -- \iDuring{#1}{#2}}
\newcommand{\ciStarts}[2]{``$#1$ started by $#2$'' -- \iStarts{#1}{#2}}
\newcommand{\ciFinishes}[2]{``$#1$ finished by $#2$'' -- \iFinishes{#1}{#2}}


\newcommand{\siBefore}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{\alpha(#2)}\ebox{\alpha(#2),\omega(#1)}\ebox{\omega(#1)}\ebox{\omega(#1),\omega(#2)}}
\newcommand{\siMeets}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{\alpha(#2)}\ebox{\omega(#1)}\ebox{\omega(#1),\omega(#2)}}
\newcommand{\siOverlaps}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{\alpha(#2)}\ebox{}\ebox{\omega(#1)}\ebox{\omega(#1),\omega(#2)}}
\newcommand{\siDuring}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{\alpha(#1)}\ebox{}\ebox{\omega(#1)}\ebox{\omega(#1),\omega(#2)}}
\newcommand{\siStarts}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{}\ebox{\omega(#1)}\ebox{\omega(#1),\omega(#2)}}
\newcommand{\siFinishes}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{\alpha(#1)}\ebox{}\ebox{\omega(#1),\omega(#2)}}
\newcommand{\siEquals}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{}\ebox{\omega(#1),\omega(#2)}}
\newcommand{\siAfter}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{\alpha(#1)}\ebox{\alpha(#1),\omega(#2)}\ebox{\omega(#2)}\ebox{\omega(#1),\omega(#2)}}
\newcommand{\siiMeets}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{\alpha(#1)}\ebox{\omega(#2)}\ebox{\omega(#1),\omega(#2)}}
\newcommand{\siiOverlaps}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{\alpha(#1)}\ebox{}\ebox{\omega(#2)}\ebox{\omega(#1),\omega(#2)}}
\newcommand{\siiDuring}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{\alpha(#2)}\ebox{}\ebox{\omega(#2)}\ebox{\omega(#1),\omega(#2)}}
\newcommand{\siiStarts}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{}\ebox{\omega(#2)}\ebox{\omega(#1),\omega(#2)}}
\newcommand{\siiFinishes}[2]{\ebox{\alpha(#1),\alpha(#2)}\ebox{\alpha(#2)}\ebox{}\ebox{\omega(#1),\omega(#2)}}


\newcommand{\projects}[3]{\bc(\rho_{#3}(#1)) = #2}
\newcommand{\projectsVoc}[2]{\projects{#1}{#2}{voc(#2)}}

\renewcommand{\sp}{~\&~}
\newcommand{\spasync}{~\&_*~}
\newcommand{\spsigma}[1][\Sigma, \Sigma']{~\&_{#1}~}
\newcommand{\spvc}{~\&_{v\!c}~}

\renewcommand{\emptyset}{\varnothing}
\renewcommand{\phi}{\varphi}

\makeatletter
\newcommand*\bigcdot{\mathpalette\bigcdot@{.5}}
\newcommand*\bigcdot@[2]{\mathbin{\vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}}}
\makeatother

\mathchardef\mhyphen="2D

% Allows entry of EventStrings as |a|{}|b,c|d|
% Use {} for empty box
\usepackage{etoolbox}
\DeclareListParser{\PipeParser}{|}
\newcommand{\EventString}[1]{
	\renewcommand*{\do}[1]{\ebox{##1}}%
	\PipeParser{#1}
}

\newcommand{\xmltag}[2][]{\texttt{\textless{}#2#1\textgreater{}}}

\defcitealias{aristotlePhysicsIV}{Physics IV}

\newcommand{\refneeded}[1][]{{\color{red}[Figure reference needed!#1]}}
\newcommand{\citeneeded}[1][]{{\color{red}[Citation needed!#1]}}

\newcommand{\selfnote}[1]{{\color{red}[NB\footnote{{\color{red}#1}}]}}
\newcommand{\nb}{\selfnote}

%\usepackage[nottoc,numbib]{tocbibind} %This includes the bibliography as a numbered section in the TOC
\usepackage[nottoc]{tocbibind}

\usepackage{cleveref}
\crefname{section}{\textbf{\S}}{\textbf{\S}}

\doublespacing
\linespread{2} %Not sure about this, may need to reset to 1(?)
\newdateformat{monthyeardate}{\monthname[\THEMONTH] \THEYEAR}

\title{\textbf{Strings for Temporal Annotation and\\Semantic Representation of Events}}

\author{by\\{\textbf{David Woods}}\bigskip\bigskip}

\date{\parbox{\linewidth}{\centering%
		{\large A dissertation submitted\\in fulfillment of the requirements\\for the Degree of\\\textbf{Doctor of Philosophy}}\\		
		\bigskip\bigskip\bigskip
		{\Large \textbf{University of Dublin, Trinity College}}\\\endgraf \monthyeardate\today}{\small \vspace{\fill} Supervised by: Dr Tim Fernando, Dr Carl Vogel}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
%                                Preamble Begins                               %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle
\thispagestyle{empty}
%\linespread{1}

\newpage
\pagenumbering{roman}
\section*{Declaration}
\addcontentsline{toc}{section}{Declaration}
\noindent
I, the undersigned, declare that this thesis has not been submitted as an exercise for a degree at this or any other university and it is entirely my own work.\par

\vspace{2em}

\noindent
I, the undersigned, agree to deposit this thesis in the University's open access institutional repository or allow the Library to do so on my behalf, subject to Irish Copyright Legislation and Trinity College Library conditions of use and acknowledgement.

%\noindent
%I, the undersigned, consent / do not consent to the examiner retaining a copy of the thesis beyond the examining period, should they so wish (EU GDPR May 2018).

\vspace{\fill}

\begin{table*}[!htbp]
	\flushright
	\begin{tabular}{l}
		\makebox[10cm]{\hrulefill}\\[0.5cm]
		David Woods\\[0.25cm]
		{\monthyeardate\today}
	\end{tabular}
\end{table*}

\vspace{5em}

\newpage
\begin{abstract}
\addcontentsline{toc}{section}{Abstract}
\noindent
%This work describes the use of strings as models for the representation of temporal data -- i.e. events and times -- to form the basis of a framework for reasoning about that data. Some of the relevant motivating literature is examined, and a breakdown is given of the work done to develop and flesh out the framework so far, including discussion on superposition for collation of information into single, timeline-like strings, and projection which allows for the identification of temporal relations between arbitrary events and times from the strings. Possible ways of treating incomplete information are also looked at, including moving from intervals as primitives to semi-intervals. Some work done to implement this framework in code is described, with a discussion of potential applications in modern intelligent systems, including tooling for annotation software.
\end{abstract}

\newpage
\section*{Acknowledgements}
\addcontentsline{toc}{section}{Acknowledgements}
%My thanks to Tim for his patience and understanding, to Carl for guiding and reassuring comments, and to my friends and family for their continuous encouragement and support. In particular, Brian, who had the misfortune to be staying with me while I was working on this report, and the members of DU Trampoline club, who have had a more bad-tempered coach of late.

I would like to thank my parents, Margaret and Graham, who never doubted I would do my best; my brother, Fergus, often a much-needed reminder of normal life; Conor and Katie, who inspired me to start; Adelais, who encouraged me to finish; and all the members of DU Trampoline Club, who gave me a reason to stick around. I hope it was worth it!

My thanks go also to my supervisors: Tim, for being patient with me even when I was struggling, and Carl, who often managed to reassure me that I wasn't going down completely the wrong path.

This research is supported by Science Foundation Ireland (SFI) through the CNGL 
Programme (Grant 12/CE/I2267) in the ADAPT Centre 
(\url{https://www.adaptcentre.ie}) at Trinity College Dublin. The
ADAPT Centre for Digital Content Technology is funded under the SFI Research 
Centres Programme (Grant 13/RC/2106) and is co-funded under the European 
Regional Development Fund.


\newpage
\section*{Related Publications}
\addcontentsline{toc}{section}{Related Publications}
% what they are and how they figure in, but don't go into it
During the course of my studies, I was an author on three papers that were accepted for publication, listed below.

\begin{itemize}
	% \citefullauthor not working??
	\item ``Towards Efficient String Processing of Annotated Events" (Woods, Fernando, and Vogel, \citeyear{woods2017towards}), describing the use of strings to model temporal data such as could be found in text annotated with ISO-TimeML. Presented at the 13th Joint ISO-ACL Workshop on Interoperable Semantic Annotation in Montpellier, France.
	\item ``Improving String Processing for Temporal Relations" (Woods and Fernando, \citeyear{woods2018improving}), discussing refinements to the previously described string-based model, such as varied granularity. Presented at the 14th Joint ISO-ACL Workshop on Interoperable Semantic Annotation, colocated with COLING 2018 in Santa F\'{e}, New Mexico, USA.
	\item ``MSO with tests and reducts" (Fernando, Woods, and Vogel, \citeyear{fernando2019mso}), discussing differing string granularities in the context of tests within Monadic Second Order logic. Presented at the 14th International Conference on Finite-State Methods and Natural Language Processing in Dresden, Germany.
\end{itemize}
\newpage
\tableofcontents
\newpage
\pagenumbering{arabic}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
%                            Actual Document Begins                            %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:intro}
This thesis will explore and describe the use of strings as models to represent temporal information---data concerning times and events---for use in computational systems which deal with knowledge-based reasoning in some way. Such systems rely on temporal information in order to perform accurately. For example, a question-answering system that is asked ``Will it rain next week?" must be able to locate itself temporally such that it knows what the current time is, the relation between that time and the queried time, and whether raining events have been forecast during the period that it defines using the phrase ``next week".
\newpage
\section{Relevant Literature}\label{sec:litreview}
In this chapter, the existing literature related to the major topics of the thesis are reviewed and analysed. A gap is identified, which the remaineder of this work seeks to fill.
\subsection{Times and Events}\label{sub:timesevents}
The concept of time has fascinated researchers for millenia, and as such, a great deal of work exists on the topic. What follows here focuses on the formal study of temporality in language.
\subsubsection{Allen Relations}\label{ssub:allen}
The seminal work of James F. Allen's \textit{Maintaining Knowledge about Temporal Intervals} has pushed the field since its publication in  \citeyear{allen1983maintaining}, and indeed the framework he described drives some of the design decisions in the present work.
\subsubsection{Tense and Aspect}\label{ssub:tenseaspect}
Reichenbach's (\citeyear{reichenbach1947elements}) theory of tense and aspect allows for the temporal placement of an event time in relation to a speech time and a reference time. The relative orderings of these three times gives rise to the categorisations of tense and aspect. \selfnote{Bring up TEA here. Also worth mentioning Vendler and Dowty in relation to lexically telic/atelic verbs, which inform the stative-based approach of the strings and thus block-compression. Tim mentioned that this is a difference from Schwer's S-Words.}
%theoretically, if event time can be an interval, so could the speech and reference times, which would lead to even more aspects
% Reichenbach, Vendler, TEA
% Aspect hypothesis of dowty - build from statives - this is behind block-compression/destuttering
% as difference for Schwer s-words
\subsection{Temporal Annotation}\label{sub:annotation}
Ideally, a human using an artificially intelligent system won't have to consider annotation, except in the case when that itself is the goal. In any case, for now annotated text is a crucial source of data for working with models such as are presented in this work. When it comes to temporal annotation, the international standard is TimeML, specifically ISO-TimeML. \selfnote{Also talk about Tango and Verhagen's T-BOX.}
% Derczinski
\subsubsection{ISO-TimeML}\label{ssub:timeml}
TimeML \citep{Pustejovsky2005} was initially designed with the goal of improving question-answering systems by marking up texts so as to give events explicit temporal locations.

TimeML vs ISO-TimeML: the ISO version is the standard. However, the TimeBank corpus uses the older version.

\subsubsection{TimeBank}\label{ssub:timebank}
The TimeBank corpus \citep{pustejovsky2006timebank} collects news articles that were manually annotated with TimeML. While it does contain some inconsistencies as a result of human error, it remains one of the largest sources for documents marked up with TimeML.
\subsection{Temporal Semantics}\label{sub:semantics}
The following sections describe some of the existing ways that the semantics of times and events can be represented. \selfnote{This section needs more---Prior's TL, FOL, SOL, Event Calculus?, Frames?, FST?}
\subsubsection{Discourse Representation Theory}\label{ssub:drt}
\citet{Kamp1993} introduced Discourse Representation Theory (DRT) as a framework for semantically representing information derived from a text. DRT separates discourse referents (the entities under discussion) from Discourse Representation Structure (DRS) conditions, which describe what is known about the referents.

\selfnote{Harry Bunt's slides from his DCLRS talk would be useful here, else ref ``A semantic annotation scheme for quantiﬁcation" (Bunt, 2019)}
% Bunt's use for semantic annotation - can we get his slides from the DCLRS?
\subsubsection{Boxer}\label{ssub:boxer}
Automatic parsing of text into DRSs is a popular task \selfnote{Find the shared task from 2019---I'm sure it was on the PMB website, but I can't find it at present}, and \citet{Bos2008} released the first version of the Boxer software which claimed to do this with over 95\% coverage for semantic analysis of newswire texts, though it was noted in the release that performance for temporal data was not as strong as its other areas.

There is a newer version of Boxer implemented as part of the Parallel Meaning Bank \citeneeded{} toolchain---however, this version had unfortunately not been made available for general use at the time of writing.

\newpage
\section{Finite-State Temporality}\label{sec:fst}
Finite-state methods may be applied to temporal semantics in an approach known as \textit{finite-state temporality} \citep{fernando2005entailments} \selfnote{Probably need to go into more detail on what FST is as defined here. Definitely need to mention why finite-state as a whole is good. Maybe mention MSO in this opening bit?}. In this chapter, strings are demonstrated as a tool of choice in modelling sequences of times and events for use within this approach. The reasoning behind the creation of such temporal strings is shown, along with their mechanics, and a discussion on the granularity of temporal information, i.e. how much ``zoom" is useful when looking at an event.

A number of operations are described for working with these strings, in particular \textit{superposition} for combining the data from multiple strings. These manipulations will prove useful when reasoning about event relations, and also in maximising data density, as will be seen.

The strings are then shown as applied to creating a functional timeline from the temporal information in a piece of text, and also how they may be useful elsewhere, such as in the area of scheduling, using a variation of the Zebra Puzzle \citeneeded{}.

\subsection{Strings for Times and Events}\label{sub:strings}
A string is a basic computational entity, defined as a finite sequence of symbols selected from some finite alphabet. They are amenable to manipulation using finite-state methods, something lacking in the infinite models of predicate logic. \nb{Should probably have a citation here?}

Strings as described and used throughout this work model the concept of inertial worlds, wherein a state will persist unless and until it is altered. The intuition for viewing inertia as a default state seems to go at least as far back as Aristotle (``But neither does time exist without change'' in \textit{\citetalias{aristotlePhysicsIV}}), and is known by the term \textit{commonsense law of inertia} \citep[p. 19]{shanahan1997solving}. This notion is also present in the Event Calculus, which represents the effects of actions on fluents in order to reason about change \citep{Kowalski1986,Miller1999,Mueller2008}. Building this inertial world view into strings allows for certain flexibilities, as real duration does not need to be accounted for when, for example, superposing strings in order to determine the relations between the events they mention (see \cref{para:str-op-sp} p. \pageref{para:str-op-sp}, \cref{ssub:superposition}). Additionally, this inertiality\nb{word?}---coupled with the fact that strings are explicit as to whether a particular fluent holds or does not hold at any particular point in time---means that the classic issue of the frame problem is avoided (see \citet[pp. 30-31]{Mccarthy69somephilosophical}).\footnote{The frame problem is an issue that can arise in first-order logic representations of the world, whereby specifying the conditions which change as the result of an action is not sufficient to entail that no other conditions have changed.}

\nb{Would be useful to discuss logical circumscription and show/discuss how strings are an application since fluents not in the vocabulary are not relevant to the string, and fluents not mentioned in a box are implicitly not true at that time point (but can be made true through superposition) -- is this still circumscription?}

\nb{Definitely should be stated somewhere how realtime durations can still be represented through fluents representing times e.g. \EventString{|sleep\mhyphen{}in,friday|friday|} or something similar}

\nb{Should also probably go into a small bit of detail about event calculus in lit. section}

\nb{Perhaps talk about forces, a la Tim's paper? since it couples with the inertia idea, i.e. nothing changes without a force to change it. It's probably too much to mention Newton's 1st law...?}

A \textit{fluent} is a condition which may change over time, and is understood here as a temporal proposition---some event, time period, or state which may change (which hereafter will also be referred to as an event, as in \citet{Pustejovsky2005}). Sets of fluents will be encoded as symbols so that any number of them may hold at once. \nb{This para sucks}

How should events be labelled? Some say an event is defined in part by its participants \citeneeded{}. Many of the procedures defined in this work which use these strings operate primarily on a syntactic level rather than depending on the lexical semantics of individual words, in order to produce an approach that works broadly. As such, in most cases, simple labels suffice for the purposes of describing the mechanics used here---this follows TimeML's standard of using labels such as \texttt{"e1"} or \texttt{"t2"} for events and times. However, it will be useful to keep reference to a fuller picture of the data when possible, particularly when drawing inferences (see \cref{ssub:inferring} and \cref{ssub:ontology}).

\subsubsection{Creating Strings}\label{ssub:creating}
% We fix a finite set A of fluents (temporal propositions), and encode sets of these fluents as symbols to allow any number of them to hold at a time (as in Fernando, 2016). A string s = α 1 · · · α n of subsets α i of A can be construed as a finite model consisting of n moments of time i ∈ {1, . . . , n} with α i specifying all fluents (in A) that (as unary predicates) hold simultaneously at i.
In order to create a string, first it is necessary to fix a finite set $\mathcal{V}$ of symbols which represent the times and events under discussion, such that each $v \in \mathcal{V}$ will be understood as naming a \textit{fluent} as a unary predicate which holds at a particular time. A string $s = \sigma_1\sigma_2\cdots\sigma_n$ of subsets $\sigma_i$ of $\mathcal{V}$ is interpreted as a finite model of $n$ moments of time, with $i \in \{1, 2, \ldots, n\}$. Each $\sigma_i$ specifies all those fluents which hold simultaneously at $i$ \nb{this is more or less the same as in ISA-13 -- should cite?}.

The set $\mathcal{V}$ will be known as a \textit{vocabulary}, and the powerset of $\mathcal{V}$ will serve as a finite alphabet $\Sigma = 2^{\mathcal{V}}$ of a string $s \in \Sigma^*$. Accordingly, at each position $i$ in the string $s$, the \textit{component} $\sigma_i$ will be a (possibly empty) set of the fluents which hold at that position.

\nb{Mention here about the box notation? Or earlier? I think here is appropriate}

Sets of strings are languages \selfnote{Maybe mention this in \cref{sub:strings} rather than here? See how it goes}. Languages allow for grouping strings based on some property, such as their source, which will permit the introduction of ambiguity as will be shown in more detail in \cref{ssub:superposition} (see p. \pageref{ex:lang-superposition}). For example,
\begin{align}
	L = \{\EventString{a|b|c}, \EventString{a|c|b}\}
\end{align}
where the language $L$ contains two strings which represent different---albeit related---sequences of events.

Note that a language containing only a single string may be conflated with its sole member, and vice versa. This is a useful admittance, particularly in regards to superposition and other string operations (see \cref{ssub:operations}), when it may be necessary to, for example, superpose a string and a language, in which case the string is conflated with a language containing just that string. \label{pt:conflation}
% This is generally a useful admittance for discussion\nb{what?} purposes when chaining together string operations, as some operations will result in a language which would be fed into a new operation.

\subsubsection{Strings as MSO Models}\label{ssub:mso}

Strings of symbols representing events as described in \cref{ssub:creating} may be interpreted as finite models of Monadic Second-Order Logic (MSO) \nb{In transfer I just pointed the reader towards \citet{Libkin2004} for a discussion -- should maybe go into at least some small detail in the main text this time? Or should that go into the lit review?}. MSO is a fragment of Second-Order Logic that restricts quantification so as to be permitted solely for unary predicates, which is equivalent to quantification over sets---this is due to the fact that a unary predicate may be effectively described by the set of terms for which that predicate is true.\citeneeded{}

This may be construed for temporal representation by considering each predicate of a model as describing an event, and the terms which make that predicate true are the moments (relative to the model) during which the associated event is occurring.

This is most clearly illustrated by means of an example. The string below in \cref{ex:mso-string} will serve for this purpose, with the positional indices shown underneath the string position with which it corresponds:
% align/alignat does column alignment as alternating left/right, so double ampersand
% gets consistent left alignment
\begin{alignat}{5}\label{ex:mso-string}
	&\EventString{{}} && \EventString{a} && \EventString{a,b} && \EventString{a} && \EventString{{}}\\[-1.2em]
	&{\scriptstyle 1} && {\scriptstyle ~2} && {\scriptstyle ~~3} && {\scriptstyle ~4} && {\scriptstyle 5}\notag
\end{alignat}
This is a string of length $5$, which contains two events, $a$ and $b$, where $b$ occurs \textit{during} $a$ (see \cref{tab:allen-rels-strings}). The linear ordering of $a$ and $b$ can be identified by the string positions in which each occurs \citep{fernando2016regular,Fernando2018}:
\begin{align}
	\llbracket P_a \rrbracket = \{2,3,4\} \text{ and } \llbracket P_b \rrbracket = \{3\}
\end{align}
where $P_a$ and $P_b$ are unary predicates, and their interpretations \nb{check that the interpretation fn is used consistently} are subsets of $\{1,2,3,4,5\}$, which is the set of all string positions for the string in \cref{ex:mso-string}.

Generally, for any string $s = \sigma_1\sigma_2\cdots\sigma_n$ with length $n \ge 0 \in \mathbb{N}$ and vocabulary $\mathcal{V}$ \nb{Should the vocabulary of all strings be $\mathcal{V}$ and the vocabulary of a particular sting be $V$?}, the set $[n]$ of string positions is defined as:
\begin{align}
	[n] := \{1,2,\ldots,n\}
\end{align}
Since $s$ is restricted to being a finitely bounded string, $[n]$ is also finite, and thus the MSO model described by $s$ will also be finite.

For each $v \in \mathcal{V}$, the predicate $P_v$ specifies all the string positions in which $v$ occurs:
\begin{align}\label{def:str-positions}
	\llbracket P_v \rrbracket := \{i \in [n] ~|~ v \in \sigma_i\}
\end{align}
The successor relation which links each string position to the next can also be defined:
\begin{align}
	S_n := \{(i, i+1) ~|~ i \in [n - 1]\}
\end{align}
If MSO$_{\mathcal{V}}$ is the set of sentences of MSO whose vocabulary is limited to $\mathcal{V}$, then an MSO$_{\mathcal{V}}$ model $mod(s)$---which is described by the string $s$---is defined by the tuple:
\begin{align}
	mod(s) := \langle [n], S_n, \{\llbracket P_v \rrbracket ~|~ v \in \mathcal{V}\} \rangle
\end{align}
Given an arbitrary MSO$_{\mathcal{V}}$ model $M$, the string $str(M)$ which describes it can be obtained by inverting \cref{def:str-positions} to get each set $\sigma_i \in str(M)$, for $i \in [n]$:
\begin{align}
	\sigma_i := \{v \in \mathcal{V} ~|~ i \in \llbracket P_v \rrbracket \}
\end{align}
\nb{Really not sure how I feel about this last bit}\citeneeded[ -- Fernando 2016 regular goes into depth about a lot of this stuff]
\nb{Need to say something about $\llbracket A \rrbracket_M$ being the interpretation of $A$ relative to the model $M$}

There is a theorem due to B\"{u}chi, Elgot, and Trakhtenbrot (see, for example, \citet[p.124, Theorem 7.21]{Libkin2004}) which states that sentences $\phi$ of MSO capture regular languages, i.e. MSO-definability is equivalent to regularity.

%%%%%%%%%%%%
\paragraph{Analogous Strings}\label{para:analogous-strings}
A string $s$ will be said to be \textit{analogous} \nb{I'm not sure where to put this section/para} to some other string $s'$ if the MSO models (see \cref{ssub:mso}) corresponding to each string are isomorphic---that is, $s$ and $s'$ are of equal length, there exists a bijective function $f$ mapping the vocabulary of $s$ to the vocabulary of $s'$, and for every $v \in \mathcal{V}_s, \llbracket P_v \rrbracket = \llbracket P_{f(v)} \rrbracket$:
\begin{align}
	s \sim s' \Longleftrightarrow  mod(s) \cong mod(s')
\end{align}
For example, in \cref{ex:analog}, \Before{a}{b} is analogous to \Before{c}{d}, while in \cref{ex:not-analog} \Before{a}{b} is not analogous to \Overlaps{c}{d}
\begin{align}
	\Before{a}{b} &\sim \Before{c}{d}\label{ex:analog}\\
	\Before{a}{b} &\nsim \Overlaps{c}{d}\label{ex:not-analog}
\end{align}
Determining whether strings are analogous is useful when ascertaining the relations between events appearing in a string. If the relations between events in a string $s$ are known, and another string $s'$ can be shown to be analogous to $s$, then the relations between the events that appear in $s'$ are also known\footnote{For example, the string on the left hand side of \cref{ex:analog} says that event $a$ is \textit{before} event $b$, and since the string on the right hand side is analogous, THEN event $c$ must be \textit{before} event $d$.}. By employing this concept in conjunction with that of projection (see p. \pageref{para:str-op-projection}) and a set of reference strings---such as those modelling Allen's relations (see \cref{tab:allen-rels-strings})---it becomes simple to determine which relations appear in a string.

Further, if a pair of strings are shown to be analogous, this can make any calculations or processing involving these strings to be more efficient: any set of operations applied to one of the strings would produce the same result if applied to the other, so there is no need to apply them to both.
%%%%%%%%%%%%

\subsubsection{Granularity: Points vs Intervals vs Semi-intervals}\label{ssub:granularity}
A decision must be made in regards to what is regarded as `primitive' in a string, in terms of whether a basic component is considered as instantaneous, or as having some duration. In the first view, only points exist, and so an event will have a beginning and an ending (left and right borders), each of which represented by a symbol in the string. In the second, entire intervals are used instead of points. Two points may only be related in three ways: \textless, =, \textgreater. Two intervals, however, may be related in thirteen different ways, precisely, the Allen Relations \citeneeded{}. 

There are advantages to each approach: ... e.g. intervals are intuitive and infinitely divisible and allow for more specific relation-labels; points are simpler and incomplete information doesn't break the system by forcing disjunctions.

A third option exists: semi-intervals, as described by \cite{Freksa1992}. By treating the borders of an event as intervals, this expands the number of available relations between two events to 31.

Ultimately, intervals are chosen for a number of reasons: primarily due to the fact that ISO-TimeML, the international standard for temporal annotation, uses intervals for its TLINKs, but also they seem the most intuitive \nb{This is vague and subjective; defend it better}.

It's worth noting that there are translations available between the different granularities.

\nb{Need to say something in here about the bounded finite intervals.}

\subsubsection{String Operations}\label{ssub:operations}
Many many operations. The most important is \textbf{superposition} (and it's more advanced forms)! Also we have block-compression, reduct, vocabulary, projection, border translations. Note also that there are equivalent operations for strings which use points instead of intervals.

\nb{Discuss the language level operations here too.}

\paragraph{Vocabulary:}
The \textit{vocabulary} $\mathcal{V}$ of a string or language is the set of fluents which appear in it. For an arbitrary string $s = \sigma_1\sigma_2\cdots\sigma_n$, the vocabulary of $s$ may be determined by taking the union of its components:
\begin{align}
	\mathcal{V}_s := \sigma_1 \cup \sigma_2 \cup \cdots \cup \sigma_n
\end{align}
and the vocabulary of a language is just the union of the vocabularies of the strings it contains:
\begin{align}
	\mathcal{V}_L := \bigcup \{\mathcal{V}_s ~|~ s \in L \}
\end{align}
% Determining a string's vocabulary permits some operations to be chained 
\paragraph{Block Compression:}
Since the length of a string $s = \sigma_1\sigma_2\cdots\sigma_n$ does not reflect its real duration (due to the understanding that strings model intertial worlds---see \cref{sub:strings} p. \pageref{sub:strings}), it is also not required that the length of time represented by any $\sigma_i$ is equal to that represented by any $\sigma_j$, for $i \neq j$. Similarly, if a fluent symbol $v \in \mathcal{V}$ from the vocabulary appears in both $\sigma_i$ and $\sigma_{i+1}$, this does not imply that the event represented by $v$ has a duration twice as long as if it had only appeared in $\sigma_i$. Indeed, the symbol $v$ may appear in any number of consecutive positions in $s$ without affecting the interpretation of the real length of time of the event it represents. Further, if the string features a repeating component, i.e. $\sigma_i = \sigma_{i+1}$ for any $1 \le i < n$, the interpretation of the string is not affected by the deletion of one of either $\sigma_i$ or $\sigma_{i+1}$. So for example, the interpretation of the string \EventString{a|a|a,b|b|b} is equal to the interpretation of the string \EventString{a|a,b|b}. A string featuring such repetitions is said to contain \textit{stutter}.

As a result, the \textit{block compression} $\bc(s)$ of a string $s$ may be introduced, which removes any stutter present in $s$. This is defined as \citep{fernando2015semantics, woods2017towards}:
\begin{align}\label{def:bc}
\bc(s) := 
\begin{cases}
	~~s & \text{if \textit{length}}(s) \leq 1\\
	~~\bc(\sigma s') & \text{if } s = \sigma \sigma s'\\
	~~\sigma \bc(\sigma' s') & \text{if } s = \sigma \sigma' s' \text{ with } \sigma \neq \sigma'
\end{cases}
\end{align}
Stutter may also be induced in a string which is \textit{stutterless} (it does not contain stutter) by using the inverse of block compression, which will generate infinitely many strings\footnote{If the string $s$ features stutter, then $\bc^{-1}(s)$ will not contain any strings with a length shorter than $s$, including $\bc(s)$. To capture all possible \bc-equivalent strings, $s$ is block compressed before the inverse is applied.}:
\begin{align}\label{def:inverse-bc}
\bc^{-1}(\bc(s)) := \sigma_1^+ \sigma_2^+ \cdots \sigma_n^+ ~~~ \mbox{ if } \bc(s) = \sigma_1 \sigma_2 \cdots \sigma_n
\end{align}
For example:
\begin{align}\label{ex:inverse-bc}
	\bc^{-1}(\EventString{a|c}) = \{\EventString{a|c}, \EventString{a|a|c}, \EventString{a|c|c}, \EventString{a|a|c|c}, \ldots\}
\end{align}
Since these strings all block compress to the same string, they can be said to be equivalent under block compression. Specifically, strings $s$ and $s'$ are \textit{\bc -equivalent} iff $\bc(s) = \bc(s')$. This ability to generate infinitely many strings which have an equivalent interpretation allows for varying the length of a string as will be required in order to form a useful notion of superposition (see p. \pageref{def:initial-async-superposition}).

\paragraph{Superposition:}\label{para:str-op-sp}
In its most basic form, the \textit{superposition} $s \sp s'$ of two strings $s = \sigma_1\sigma_2\cdots\sigma_n$ and $s' = \sigma'_1\sigma'_2\cdots\sigma'_n$ of equal length $n$ is simply their component-wise union\footnote{The vocabulary of the resulting string is, as might be expected, the union of the vocabularies of the original strings: $\mathcal{V}_{s \sp s'} = \mathcal{V}_s \cup \mathcal{V}_{s'}$.}:

\begin{align}\label{def:superposition}
	\sigma_1\sigma_2\cdots\sigma_n \sp \sigma'_1\sigma'_2\cdots\sigma'_n := (\sigma_1 \cup \sigma'_1)(\sigma_2 \cup \sigma'_2)\cdots(\sigma_n \cup \sigma'_n)
\end{align}
For example:
\begin{align}\label{ex:superposition}
	\EventString{a|b|c} \sp{} \EventString{a|c|d} = \EventString{a|b,c|c,d}
\end{align}
This is easily extended to pairs of languages $L \sp L'$ by collecting the superpositions of strings of equal lengths in each language:
\begin{align}\label{def:lang-superposition}
	L \sp L' := \bigcup_{n \ge 0}\{ s \sp s' | s \in L \cap \Sigma^n, s' \in L' \cap \Sigma^n\}
\end{align}
The result $L \sp L'$ of superposing two languages $L$ and $L'$ is also a language \nb{Don't forget to mention the connection to regular languages and FSA here}, and if $L$ and $L'$ are regular languages, then $L \sp L'$ is also regular. If $L$ is accepted by the finite automaton $\langle Q, (2^\mathcal{V})^*, (q \sta{\sigma}{\to} r), q_0, F \rangle$ and $L'$ is accepted by the finite automaton $\langle Q', (2^{\mathcal{V}'})^*, (q' \sta{\sigma'}{\to} r'), q'_0, F' \rangle$ then $L \sp L'$ is computed by a finite automaton composed of the automata accepting each $L$ and $L'$: $\langle Q \times Q', (2^{\mathcal{V} \cup \mathcal{V}'})^*, ((q, q') \sta{(\sigma \cup \sigma')}{\to} (r, r')), (q_0, q'_0), F \times F' \rangle$. \nb{expand on this and its importance}

Using languages provides more flexibility than strings alone, since non-determinism can be accounted for through variations between strings within a language. For example, in \cref{ex:lang-superposition} below, the result of the superposition accounts for the alternate event sequences in the strings of the first input language.
\begin{align}\label{ex:lang-superposition}
	\{\EventString{a|b|c}, \EventString{a|c|b}\} \sp \{\EventString{a|c|d}\} = \{\EventString{a|b,c|c,d}, \EventString{a|c|b,d}\}
\end{align}
This may reflect a situation where there is uncertainty as to the correct order of events---in this case a language is useful to collect all of the possible alternatives, which can then be still be superposed with other languages. 

\paragraph{Asynchronous Superposition:}\label{para:str-op-sp-async}
In order to extend this operation further, it is necessary to remove the restriction that only strings of equal length may be superposed together. This is desirable so as to allow arbitrary numbers of events to appear in strings, and to superpose strings which may be of unknown length. For example, the operation in \cref{ex:unequal-lengths} below cannot be calculated, and even if the strings were instead singleton members of languages and those languages were superposed, the result would just be the empty set.
\begin{align}\label{ex:unequal-lengths}
	(\EventString{a|b} \sp \EventString{c|d}) \sp (\EventString{a|b|c} \sp \EventString{a|c|d})
	= \EventString{a,c|b,d} \sp \EventString{a|b,c|c,d}
	= undefined
\end{align}
To achieve this, \bc-equivalence is exploited and the \textit{inverse block compression} operation (see \cref{def:inverse-bc}, p. \pageref{def:inverse-bc}) is leveraged. Since, by inducing stutter in a string, infinitely many new strings of greater or equal length can be generated which are \bc-equivalent to the starting string, it is effectively possible to force a pair of strings to be of equal length.

So, the \textit{asynchronous superposition} $s \spasync s'$ of two strings $s$ and $s'$ is initially defined as the language obtained by applying block compression to the results of superposition between the languages which are respectively \bc-equivalent to each of $s$ and $s'$\footnote{Note that $\bc(s) = \bc(s') \Longleftrightarrow s \in \bc^{-1}(\bc(s'))$}:
\begin{align}\label{def:initial-async-superposition}
	s \spasync s' := \{\bc(s'') ~|~ s'' \in \bc^{-1}(\bc(s)) \sp \bc^{-1}(\bc(s'))\}
\end{align}
Now the strings in \cref{ex:unequal-lengths} can be superposed using asynchronous superposition, as in \cref{ex:async-superposition} below: \nb{double check the below output, not sure of prolog quality... (turing:www/super/superposition.pl)}
% | ?- spbc_set([[a,c],[b,d]], [[a],[b,c],[c,d]], L).
% L = [
% 	[[a,c],[a,b,c],[a,c,d],[b,c,d]],
% 	[[a,c],[a,b,c],[b,c,d]],
% 	[[a,c],[a,b,d],[b,c,d]],
% 	[[a,c],[b,c,d]]
% 	].

\begin{align}\label{ex:async-superposition}
	\EventString{a,c|b,d} \spasync \EventString{a|b,c|c,d} = \{&\EventString{a,c|a,b,c|b,c,d}, \EventString{a,c|a,b,d|b,c,d},\\&\EventString{a,c|a,b,c|a,c,d|b,c,d}, \EventString{a,c|b,c,d}\}\notag
\end{align}
However, one slightly problematic aspect of this definition is the fact that $\bc^{-1}$ maps from a string to an infinite language. While this is not an issue from a theoretical standpoint, since $\spasync$ collects the set of block compressed strings from the superposition of these languages, from a practical and computational standpoint anything infinite is inconvenient.

In order to tackle this back to something finite and to avoid generation of large amounts of redundant information, in \citet[p. 127]{woods2017towards} an upper bound of $n + n' - 1$ is established for the maximum length of any string produced via asynchronous superposition $s \spasync s'$, where $n$ and $n'$ are the (nonzero) lengths of the strings $s$ and $s'$, respectively. This work additionally introduces the operation $pad_k$, which will perform inverse block compression on a string, but will only produce strings of a given length $k > 0$:
\begin{align}\label{def:padk}
	pad_k(\bc(s)) &:= \sigma_1^+ \sigma_2^+ \cdots \sigma_n^+ \cap \Sigma^k ~~~ \mbox{ if } \bc(s) = \sigma_1 \sigma_2 \cdots \sigma_n\\
	&=\{\sigma_1^{k_1}\sigma_2^{k_2}\cdots\sigma_n^{k_n} ~|~ k_1,\ldots,k_n \ge 1, \sum_{i = 1}^{n}k_i = k  \}\notag
\end{align}
The language produced by padding a string is a proper subset of the language produced by performing inverse block compression on that same string. For example, using the same string as \cref{ex:inverse-bc}:
\begin{align}\label{ex:padk}
	pad_3(\EventString{a|c}) = \{\EventString{a|a|c}, \EventString{a|c|c}\}
\end{align}
By using this padding operation in place of the inverse block compression in an updated definition of asynchronous superposition, setting $k$ to be the upper bound derived from the lengths of the input strings, the issue of going beyond finite sets is avoided without losing any of the power of using \bc-equivalence:
\begin{align}\label{def:async-superposition}
	% \text{\textit{For any strings }}s\text{\textit{ and }}s'\text{\textit{ with nonzero lengths $n$ and $n'$, respectively}}\notag\\
	s \spasync s' := \{\bc(s'') ~|~ s'' \in pad_{n+n'-1}(s) \sp pad_{n+n'-1}(s')\}
\end{align}
It's worth noting here that neither basic superposition $\sp$ nor asynchronous superposition $\spasync$ place any importance on the semantic content contained within the strings over which they operate. That is to say, they are entirely syntactical operations, and any meaningful information represented by a given string is liable to be lost once it has been superposed with some other string.

For instance, in \cref{ex:superposition}, the second of the operand strings has the event $c$ appearing in a box to the left of (before) the event $d$, whereas the result has $c$ and $d$ occuring in the same box together, which states that they were occurring at the same moment.

Similarly, in \cref{ex:async-superposition}, the first input string has events $a$ and $c$ appearing in the same box, while the second input string has $a$ appearing in a box before $c$. While this should seem like a contradiction which should not have viable results, the operation instead produces a set of strings.

This stands in contrast to the concept of \bc-equivalence, where strings have an equal interpretation regardless of how much or how little stutter is present. By using superposition as is currently presented, information is in fact lost rather than gained when strings are combined. The next two operations aim to resolve this issue.

\paragraph{Reduct:}\label{para:str-op-reduct}
It will be useful to be able to alter the vocabulary of a string---in particular, to shrink it---so as to control which events are mentioned. If a string contains, for instance, five events, but only two of these are relevant to the application, there is sense in being able to focus on those two.

As such, for any set $A$, the $A$-\textit{reduct} $\rho_A$ of a string $s=\sigma_1\sigma_2\cdots\sigma_n$ is defined as the componentwise intersection of $s$ with $A$ \citep{fernando2016regular,woods2018improving}:
\begin{align}
	\rho_A(\sigma_1\sigma_2\cdots\sigma_n) := (\sigma_1 \cap A)(\sigma_2 \cap A)\cdots(\sigma_n \cap A)
\end{align}
The resulting new string has a vocabulary of $A$, but the remaining fluents are still in the same relative positions to each other as in the original:
\begin{align}
	\mathcal{V}_{\rho_A(s)} &= A\\
	(\forall a \in A)~\llbracket P_a \rrbracket_{mod(s)} &= \llbracket P_a \rrbracket_{mod(\rho_A(s))}
\end{align}
For example, with the string $s = \EventString{{}|a,b|a,b,c|a,c,d|a,e|e|{}}$ and $A=\{a,d\}$, the $A$-reduct of $s$ is:
\begin{align}\label{ex:reduct}
	\rho_{\{a,d\}}(\EventString{{}|a,b|a,b,c|a,c,d|a,e|e|{}}) = \EventString{{}|a|a|a,d|a|{}|{}}
\end{align}
The resulting string in \cref{ex:reduct} contains only the events of interest (those mentioned in $A$), without loss of information. That is, the relative ordering of the events in the result string is the same as that in the input. The result string can additionally be block compressed to derive the simplest representation of the information it contains\footnote{In the case of \cref{ex:reduct,ex:bc-reduct}, the event $a$ \textit{contains} the event $d$, according to Allen's relations \citep{allen1983maintaining}\refneeded.}:
\begin{align}\label{ex:bc-reduct}
	\bc(\EventString{{}|a|a|a,d|a|{}|{}}) = \EventString{{}|a|a,d|a|{}}
\end{align}

\paragraph{Projection:}\label{para:str-op-projection}
This process is streamlined through the use of \textit{projection}, where the $A$-projection $\pi_A$ of a string $s$ is simply the block compressed reduct of $s$ relative to $A$:
\begin{align}
	\pi_A(s) := \bc(\rho_A(s))
\end{align}
It will be said that a string $s$ \textit{projects to} another string $s'$, $s \sqsupseteq s'$, if the $\mathcal{V}_{s'}$-projection of $s$ is equal to $s'$:
\begin{align}
	s \sqsupseteq s' \Longleftrightarrow  \pi_{\mathcal{V}_{s'}}(s) = s'
\end{align}
If $s$ projects to $s'$, then all of the information represented within $s'$ is also represented in $s$---$s$ effectively ``contains'' $s'$.

Borrowing from the examples in \cref{ex:reduct,ex:bc-reduct}, the temporal data represented by the string on the right hand side of \cref{ex:projects-to} is also contained in the string on the left hand side:
\begin{align}\label{ex:projects-to}
	\EventString{{}|a,b|a,b,c|a,c,d|a,e|e|{}} \sqsupseteq \EventString{{}|a|a,d|a|{}}
\end{align}
It is worth noting that, if strings $s$ and $s'$ share the same vocabulary, but are not equal, then neither can $s$ project to $s'$ nor $s'$ project to $s$---this scenario suggests that $s$ and $s'$ are incompatible, that they describe contradictory sequences of the same events:
\begin{align}\label{impl:cannot-project}
	\mathcal{V}_s = \mathcal{V}_{s'} \wedge s \neq s' \Longrightarrow \lnot (s \sqsupseteq s' \lor s' \sqsupseteq s)
\end{align}
A language $L$ can be said to project to another language $L'$ if every string $s \in L$ projects to every string $s' \in L'$:
\begin{align}
	L \sqsupseteq L' \Longleftrightarrow  (\forall s \in L)(\forall s' \in L')~s \sqsupseteq s'
\end{align}
This notion of projection is particularly useful, allowing for temporal reasoning when used in conjunction with the concept of \textit{analogous} strings (see \cref{para:analogous-strings}, p. \pageref{para:analogous-strings}). Particular events can be simply extracted from larger, more complex strings, and compared against reference to determine the relations between and ordering of the events of interest.

Importantly, projection will also be used to enrich the asynchronous superposition (see p. \pageref{def:async-superposition}) operation, injecting the currently-lacking ``semantic-ness'' by ensuring that all results of superposing a pair of strings project to each of their input strings.

\paragraph{Vocabulary-constrained Superposition:}
The current core issue with asynchronous superposition $\spasync$ is that data can become lost or ``corrupted'' when combining strings. In general, if a string generated by superposition does not project back to both of the strings that were superposed to generate it, then information has been lost.

For example, in \cref{ex:async-superposition} (p. \pageref{ex:async-superposition}), none of the result strings contain the information that is represented in the input strings. This can be verified by testing whether any string in the result set projects to either of the inputs, which they do not:
\begin{center}
	\begin{tabular}[h!]{r c l | r c l}
		\EventString{a,c|a,b,c|b,c,d}&$\not\sqsupseteq$&\EventString{a,c|b,d}&\EventString{a,c|a,b,c|b,c,d}&$\not\sqsupseteq$&\EventString{a|b,c|c,d}\\
		\EventString{a,c|a,b,d|b,c,d}&$\not\sqsupseteq$&\EventString{a,c|b,d}&\EventString{a,c|a,b,d|b,c,d}&$\not\sqsupseteq$&\EventString{a|b,c|c,d}\\
		\EventString{a,c|a,b,c|a,c,d|b,c,d}&$\not\sqsupseteq$&\EventString{a,c|b,d}&\EventString{a,c|a,b,c|a,c,d|b,c,d}&$\not\sqsupseteq$&\EventString{a|b,c|c,d}\\
		\EventString{a,c|b,c,d}&$\not\sqsupseteq$&\EventString{a,c|b,d}&\EventString{a,c|b,c,d}&$\not\sqsupseteq$&\EventString{a|b,c|c,d}\\
	\end{tabular}
	\captionof{figure}{Failed projections for \cref{ex:async-superposition}}\label{tab:failed-projections}
\end{center}
In fact, every string in \cref{ex:async-superposition} shares the same vocabulary, so by \cref{impl:cannot-project}, it is not possible for any to project to any other. It is, in general, possible for asynchronous superposition $s \spasync s'$ to produce results such that they can project to the strings $s$ and $s'$ which generated them (see \cref{ex:overgen} below). However, in the case where the vocabularies of the two strings are identical, then none of the results will project to the original strings. In fact, the intersection of the vocabularies of $s$ and $s'$ can be used to determine whether none, some, or all of the results will project back\footnote{Assuming that $s \neq s'$.}:
\begin{subequations}
	\begin{align}
		\mathcal{V}_s \cap \mathcal{V}_{s'} = \mathcal{V}_s = \mathcal{V}_{s'} &~\Longrightarrow~ \forall s'' \in s \spasync s'~\lnot(s'' \sqsupseteq s \lor s'' \sqsupseteq s')\label{impl:voc-intersectionA}\\
		\mathcal{V}_s \cap \mathcal{V}_{s'} = \emptyset &~\Longrightarrow~ \forall s'' \in s \spasync s'~(s'' \sqsupseteq s \land s'' \sqsupseteq s')\label{impl:voc-intersectionB}\\
		\text{else} &~\Longrightarrow~ \exists s'' \in s \spasync s'~(s'' \sqsupseteq s \lor s'' \sqsupseteq s')\label{impl:voc-intersectionC}
	\end{align}
\end{subequations}
\nb{\cref{impl:voc-intersectionA} follows from \cref{impl:cannot-project}, and the next one is true because disjoint vocabs, and the last one iunno it just is. Maybe leave out this line.}

%%%%%%%%%
Here goes the bit that says that \citet{woods2017towards} used generation then test, but this was sloooooow. Then magical \citet{woods2018improving} did generation AND test, and that was like totes way better yo.
\begin{align}\label{ex:overgen}
	sooooo many strings
\end{align}
%%%%%%%%%

\subsection{Applications}\label{sub:applications}
The following will outline some of the ways that the use of string-based FST can applied to problems in NLP.

\subsubsection{Timelines from Texts}\label{ssub:timelines}
Strings, as entities comprised of sequential components, have an intuitive comparison to a traditionally linear view of time. That is, that events which have not yet occurred are ahead of us, and events which occurred in the past are behind us---though not all languages or cultures perceive time in this way, it is common cross-linguistically to use some spatial reference points when discussing temporality \citeneeded[ -- see Sec 1 para 1 of: \url{https://onlinelibrary.wiley.com/doi/full/10.1111/cogs.12804}]{}. Regardless of spatial orientation, this perception of time maps well to a sequential representation as is found with strings. Perceived directionality of time is not an issue, as it is a small modification to change the direction of a string.

A lot of information can be derived from a text document, depending on what one is looking for. Here, the focus is on isolating the events and times that are mentioned or implied in the text. By extracting this information, a timeline is built which gives a picture of the content of the document, which may reveal insights not obvious when looking at the text as a whole.

\nb{dunno where this table goes yet, just fixing the broken reference}
\nb{decide about (consistently) using `b' or `\textless' for the before relation}
\begin{center}
	\onehalfspacing
	\begin{tabular}{c|c|c||c|c|c}
		$R$ & $a~R~b$ & $\mbox{$\cal{S}$}_R(a,b)$ & $R^{-1}$ & $a~R^{-1}~b$ & $\mbox{$\cal{S}$}_{R^{-1}}(a,b)$ \\
		\hline
		$<$ & $a$ before $b$ & \Before{a}{b} & $>$ & $a$ after $b$ & \After{a}{b} \\
		
		m & $a$ meets $b$ & \Meets{a}{b} & mi & $a$ met by $b$ & \iMeets{a}{b} \\
		
		o & $a$ overlaps $b$ & \Overlaps{a}{b} & oi & $a$ overlapped by $b$ & \iOverlaps{a}{b} \\
		
		d & $a$ during $b$ & \During{a}{b} & di & $a$ contains $b$ & \iDuring{a}{b} \\
		
		s & $a$ starts $b$ & \Starts{a}{b} & si & $a$ started by $b$ & \iStarts{a}{b} \\
		
		f & $a$ finishes $b$ & \Finishes{a}{b} & fi & $a$ finished by $b$ & \iFinishes{a}{b} \\
		
		= & $a$ equals $b$ & \Equals{a}{b} & & &
	\end{tabular}
	\captionof{figure}{Allen interval relations in strings}\label{tab:allen-rels-strings}
\end{center}

\subsubsection{Inferring New Information}\label{ssub:inferring}
A text which has been manually annotated for temporal information will typically mark up the most important relations between events, at least as the annotator saw them. By extracting and making plain the timeline, any inconsistencies are immediately revealed, whether these are the fault of a problematic document or human error. Further, relations between times and events which were not previously obvious can be spelled out clearly.

This can be extended over multiple documents by keeping track of the semantics of the elements in a string---being able to map between the symbols and their meanings---and linking documents which refer to the same events. This can provide a way for checking consistency between reports which originate from different sources, or a way for augmenting an existing timeline with new data.

Additionally, conclusions can be drawn about whether certain inferences can be made based on existing data by determining the gap between premise strings and strings representing the question statement. That is, deriving the information that could be added to the premises to make the conclusion consistent with the known information (see \cref{ssub:residuals}).

\subsubsection{Scheduling (Zebra Puzzle)}\label{ssub:zebra}
Scheduling is a problem. The Zebra/Einstein Puzzle is another problem. They may seem dissimilar, but in fact, there are a number of parallels. Both problems can be viewed as constraint satisfaction problems. Although the Zebra Puzzle concerns physical constraints, these can be modelled as sequences for which one can use strings to represent. If a ``house" is conceptualised as a box in a string i.e. a set, the elements contained within are the properties of that house according to the puzzle. For example, $\{red, english, zebra, oj, kools\}$. The left/right spatial relations are thought of in the same way as the previous/next boxes in a string.

Below is presented a variant of the puzzle using clues pertaining to temporal relations instead of spatial ones.
%\newpage
%a
%\newpage
%a
%\newpage
%a
%\newpage
%a
%\newpage
%a
%\newpage
%a
%\newpage
%a
%\newpage
%a
%\newpage
%a

\newpage
\section{Methods}\label{sec:methods}
This chapter details the approaches that were taken to produce the results.

\subsection{Extracting Strings from Annotated Text}\label{sub:extracting}
The primary source of data is the TimeBank corpus which is one of the largest available collections of documents which are annotated with TimeML. Events are marked up with an \xmltag{EVENT} tag, and times with the \xmltag{TIMEX3} tag. Within TimeML, they are treated as intervals (see \cref{ssub:granularity}) which becomes relevant to the present work in the way they are related.

\subsubsection{TLINKs}\label{ssub:tlinks}
TimeML primarily uses \xmltag{TLINK} tags to annotate relations between marked up events and times. These serve as the basis for initial string creation, as they provide the two intervals that are being related, as well as the relation between them. The relation set used is specific to TimeML, but has its roots in the set of Allen Relations---see table \refneeded{} below.

A translation is built from \xmltag{TLINK} to string, using the tag's attributes to provide the data, and the Allen Relations as an intermediary step, as per table \refneeded{}. For example: \nb{example here please}. Any events and times that feature in the document but are not mentioned in a \xmltag{TLINK} are kept aside for now, as there is not a given connection from these events to the rest of the timeline.

After creating strings from the \xmltag{TLINK}s, the next step is to start building the timeline, using the superposition technique described in \cref{ssub:operations}. This allows for connections to be built between events and times that were not explicitly related by the annotation. If every time and event in the text is related to every other time and event, there is \textit{temporal closure} in the text (see \cref{ssub:allen} \nb{See transfer p6 -- maybe include the graph of $n(n-1)/2, n \ge 2$?}). For there to be temporal closure in a TimeML document would be a large amount of work for an annotator, as for $N$ events/times there would be $N(N - 1) / 2$ relations between them, which increases quickly: at $N = 10$ there are 45 relations, at $N = 50$ there are 1225 relations. This becomes unwieldy for a human to annotate, especially given that it is generally understood by the human reader that if $A$ precedes $B$, and $B$ precedes $C$, then $A$ also precedes $C$, so it feels unnecessary to include this latter relation. However, an automated system does not have this inherent knowledge, and needs a way to calculate the implied relations.

The various relations can be combined according to the table in \cite{allen1983maintaining} \citeneeded[ -- get the page and figure number], reproduced in \cref{ssub:allen} \refneeded{}, and again below using strings in table \refneeded{}. The advantage to using strings is that the extension beyond three events is simple \nb{Defend this -- I think there is something in ISA13 paper -- or remove}. It should be noted that several combinations of relations produce a disjunction of relations, which follows from the fact that these combinations of $a \bigcdot b$ and $b \bigcdot c$ don't provide enough information to determine the exact relation $a \bigcdot c$. It may be possible to narrow this down, though, with the addition of further relations connecting other intervals ($d,e,f,...$) with some or all of $a,b,c$.

\subsubsection{Handling Incomplete Data}\label{ssub:incomplete}
When dealing with any temporal information, there is often a lack of specificity that means temporal closure cannot be calculated. For example, knowing that event $a$ occurred before event $c$ \Before{a}{c} and that event $b$ also occurred before $c$ \Before{b}{c} does not impart any information on the relation between $a$ and $b$. If this is all of the available data, then it is only possible to choose this relation $a \bigcdot b$ with a precision of $\frac{1}{13}$ chance. However, further information which includes other relations for each of $a$ and $b$ individually may eventually reveal their connection.

See also, using semi-intervals to simplify disjunctions of Allen Relations. Minimal sets of maximal strings.

Freksa relations using semi-intervals: the appearance of $\alpha(a)$ within a box represents a negation of the fluent $a$ conjoined with a formula stating that $a$ will be true in a subsequent box; similarly, $\omega(a)$ represents a negation of the fluent $a$ conjoined with a formula stating that $a$ was true in a previous box.

\begin{align}
%\alpha_a(x) := x \notin P_a \land \exists y(x < y \land y \in P_a \land \forall z(z < y \rightarrow z \notin P_a))\\
%\omega_a(x) := x \notin P_a \land \exists y(y < x \land y \in P_a \land \forall z(y < z \rightarrow z \notin P_a))
\alpha_a(x) := \exists y(x < y \land y \in P_a \land \forall z(z < y \rightarrow z \notin P_a))\\
\omega_a(x) := \exists y(y < x \land y \in P_a \land \forall z(y < z \rightarrow z \notin P_a))
\end{align}
Note that it is convenient to write $\alpha(a)$ for $\alpha_a(x)$ when using the box-notation.

A string may be translated to one using semi-intervals by placing $\alpha(f)$ in every box preceding one in which a fluent $f$ appears, and $\omega(f)$ in every box succeeding it, repeating this for each $f \in A$.\par
Thus a string 
\begin{align}
	s = \EventString{{}|a|b|{}}
\end{align}
becomes \nb{decide on semin-interval translation fn symbol}
\begin{align}
	\left\lceil s\right\rceil = \EventString{\alpha(a),\alpha(b)|\alpha(b)|\omega(a)|\omega(a),\omega(b)}
\end{align}
in which each of the fluents originally appearing in the string $s$ have also been removed in . It should be noticed that strings which use semi-intervals do not (necessarily) feature empty boxes at each end. This is due to the fact that a semi-interval need not be finitely bounded. In fact

This mechanism allows for partially known information to be represented using strings. For example, the string \EventString{\alpha(a), \alpha(b)|{}} represents the knowledge that the events labelled $a$ and $b$ both begin at the same moment, without stating anything about when they each finish---they may end simultaneously, $a$ may finish before $b$, or $b$ may finish before $a$. Which of these states is true is unknown without further data.

Semi-intervals allow for representing a greater range of event relations than the Allen relations do alone. Freksa \citeneeded{} describes 18 new relations which are made up of disjunctions of Allen's relations, based on the concept of cognitive neighbourhoods. That is, groupings of relations that make intuitive sense and can be derived from compositions of Allen relations \nb{expand, clarify ``intuitive", decide between Allen/Allen's, try to use less ``relations"?} \nb{include table or graphic of Freksa's relations, eg p18 or p21}.

Many of the Freksa relations can be captured using the semi-intervals \nb{duh, he designed them that way} in the box-notation.

For example, the relation \textit{older} corresponds with a disjunction of five Allen relations: \textit{before}, \textit{meets}, \textit{overlaps}, \textit{contains}, and \textit{finished by}.
\begin{figure}[h]
	\begin{align*}
	\text{before -- }&\Before{a}{b}\\
	\text{meets -- }&\Meets{a}{b}\\
	\text{overlaps -- }&\Overlaps{a}{b}\\
	\text{contains -- }&\iDuring{a}{b}\\
	\text{finished by -- }&\iFinishes{a}{b}
	\end{align*}
	\caption{The Freksa relation \textit{older}}
\end{figure}
The similarities between these five relations becomes more apparent when they are translated to use semi-intervals instead:
\begin{figure}[h]
	\begin{align*}
	\text{before -- }&\siBefore{a}{b}\\
	\text{meets -- }&\siMeets{a}{b}\\
	\text{overlaps -- }&\siOverlaps{a}{b}\\
	\text{contains -- }&\siiDuring{a}{b}\\
	\text{finished by -- }&\siiFinishes{a}{b}
	\end{align*}
	\caption{The Freksa relation \textit{older} using semi-intervals, before block-compressed reduct}
\end{figure}

Each of these five strings projects (using a block-compressed reduct) to the string \EventString{\alpha(a),\alpha(b)|\alpha(b)|{}}, meaning the relation $a$ \textit{older} $b$ can be represented using just this one string, instead of five. This does raise the question, however, of whether the tradeoffs are worth it: a great reduction in the cardinality of the timeline set can be achieved, but at the cost of using a more complex vocabulary and reducing the precision of the known information.

Unfortunately, only 10 of the 18 Freksa relations can be described using a single string without further complicating the vocabulary which may appear within a box in a string. Since all of these new relations are disjunctions of Allen relations, it follows that it may be acceptable to include disjunctions of semi-intervals inside a box, such as \ebox{\alpha(a) \lor \alpha(b)}, which is interpreted as one might expect: either $\alpha(a)$ appears in the box, or $\alpha(b)$ does, or they both do. This allowance admits a further 5 Freksa relations to be described in single strings. Of the remaining 3 relations, the \textit{unknown} relation may also be described using a single string, but it is trivial, since it encompasses a disjunction of all 13 Allen relations, and is formed by a simple disjunction of all possible semi-inteval symbols: \ebox{\alpha(a) \lor \alpha(b) \lor \omega(a) \lor \omega(b) \lor \epsilon}, or even more simply, with a string consisting of just a single empty box: \ebox{}.

Below is a table of the 18 Freksa relations, the Allen relations they comprise, and the string which they will project to. \nb{tidy up ordering of allens}

\begin{figure}[h]
	\footnotesize
	\begin{center}
	\begin{tabular}{c | c | c}
		\hline
		Freksa & Allen & string\\
		\hline
		unknown & b, bi, m, mi, s, si, f, fi, d, di, o, oi, e & \ebox{}\\
		older & b, m, o, di, fi & \EventString{\alpha(a),\alpha(b)|\alpha(b)|{}}\\
		younger & bi, mi, oi, d, f & \EventString{\alpha(a),\alpha(b)|\alpha(a)|{}}\\
		head to head & s, si, e & \EventString{\alpha(a),\alpha(b)|{}}\\
		tail to tail & f, fi, e & \EventString{{}|\omega(a),\omega(b)}\\
		survived by & b, m, s, d, o & \EventString{{}|\omega(a)|\omega(a),\omega(b)}\\
		survives & bi, mi, si, di, oi & \EventString{{}|\omega(b)|\omega(a),\omega(b)}\\
		born before death & b, m, s, si, f, fi, d, di, o, oi, e & \EventString{\alpha(a)|{}|\omega(b)}\\
		died after birth & bi, mi, s, si, f, fi, d, di, o, oi, e & \EventString{\alpha(b)|{}|\omega(a)}\\
		precedes & b, m & \EventString{\alpha(b) \lor \omega(a)}\\
		succeeds & bi, mi & \EventString{\alpha(a) \lor \omega(b)}\\
		contemporary & s, si, f, fi, d, di, o, oi, e & \EventString{\alpha(a) \lor \alpha(b)|{}|\omega(a) \lor \omega(b)}\\
		older contemporary & o, fi, di & \EventString{\alpha(a),\alpha(b)|\alpha(b)|{}|\omega(a) \lor \omega(b)}\\
		younger contemporary & oi, f, d & \EventString{\alpha(a),\alpha(b)|\alpha(a)|{}|\omega(a) \lor \omega(b)}\\
		surviving contemporary & di, si, oi & \EventString{\alpha(a)|{}|\omega(b)|\omega(a),\omega(b)}\\
		survived by contemporary & d, s, o & \EventString{\alpha(b)|{}|\omega(a)|\omega(a),\omega(b)}\\
		older and survived by & b, m, o & ...\\
		younger and survives & bi, mi, oi & ...\\
	\end{tabular}
	\end{center}
	\caption{The Freksa relations and the strings they project to}
\end{figure}
The last two relations on this list cannot be represented using a single string, and are instead must use conjunctions of pairs of strings: 
\begin{figure}[h]
	\footnotesize
	\begin{center}
		\begin{tabular}{c | c | c}
			\hline
			Freksa & Allen & strings\\
			\hline
			older and survived by & b, m, o & \EventString{\alpha(a),\alpha(b)|\alpha(b)|{}} $\land$ \EventString{{}|\omega(a)|\omega(a),\omega(b)}\\
			younger and survives & bi, mi, oi & \EventString{\alpha(a),\alpha(b)|\alpha(a)|{}} $\land$ \EventString{{}|\omega(b)|\omega(a),\omega(b)}\\
		\end{tabular}
	\end{center}
	\caption{The remaining Freksa relations and the strings they project to}
\end{figure}

While having to use a conjunction of strings may seem like a confounding issue which prevents all the relations from being representable by a single string, it is in fact less problematic than allowing disjunction inside a box, in some ways.
\subsection{Enhancing Strings using DRT}\label{sub:enhancing}
Automatic DRS-parsing of plain text is a task which has recently seen new approaches \citeneeded[ -- shared task, see fsmnlp paper sec 1]. It is possible to leverage the temporal information that features in a DRS to create strings. While the relations generally found using this approach are less specific than those found in TimeML \nb{compare the relations}, the advantage of using DRSs is that elements such as event participants are described.

Boxer \citep{Bos2008} is one available tool for parsing a text into one or more DRSs, though the temporal information in this version struggles a bit. A newer version of the tool is used as part of the Parallel Meaning Bank \citeneeded toolchain, although it has not been made publicly available at present.

\subsubsection{Parallel Meaning Bank}\label{ssub:pmb}
Under the assumption that the version of Boxer that is used in PMB would become available at some point, here is a description of PMB, and how the present work utilises the data within it as a demonstration of using text that has been parsed into DRSs can be transformed into strings for temporal reasoning.

Discourse relations are also a thing here.

\subsubsection{VerbNet and WordNet}\label{ssub:verbwordnet}
Two resources which are used in PMB and that can be leveraged are VerbNet, which supplies the semantic roles in a DRS, and WordNet, which is used to specify the particular sense of a verb (or other word). The version of Boxer used in the PMB includes this information in its output.

This data can be useful when trying to make links between events which have not been given a specific relation. For example, finding the closest hypernym between two verbs, or checking verbs which share participants may help to inform the building of relations (see \cref{ssub:ontology}).

\subsection{Reasoning with Strings}\label{sub:reasoning}
Strings of events are used to reason about the temporal information they contain: to infer a linear ordering and new relations between the events that were not previously stated. There are several methods which can be employed depending on the specific results that are desired.

Superposition of strings creates new strings which feature all of the constraints of their ``parent" strings, and new relations can be derived by taking the projections of these strings in relation to an intersection of the parent vocabularies. Using resources such as VerbNet and WordNet (see \cref{ssub:verbwordnet}), the lexical semantics can be leveraged in order to suggest links between events which were not previously explicitly related. Additionally, residuals are employed to determine what relations may need to hold in order for other inferences to be made.

\subsubsection{Superposition and Projection}\label{ssub:superposition}
Having extracted strings from an annotated document, such as one of those in the TimeBank \citeneeded{} corpus, superposition can be used to work out the relations which are not yet made explicit. Strings model sets of constraints between the events they mention, and when two strings are superposed, all of these constraints also hold in the resulting language's strings. This can be shown through an example:
\begin{align}
\Before{a}{b} \spvc \Before{b}{c} = \EventString{{}|a|{}|b|{}|c|{}}
\end{align}
The constraint that event $a$ occurs before event $b$ holds in $s = \Before{a}{b}$, and also in the resulting string\footnote{Note that the result of a superposition is a language, but if its cardinality is 1, it can be conflated with its sole member string.} $s'' = \EventString{{}|a|{}|b|{}|c|{}}$. In order to prove this, take the \textit{projection} \refneeded[-- ref section 3.1]{} of $s''$ with respect to the vocabulary of $s$, and see that it is equal to $s$:
\begin{align}
\pi_{voc(s)}(s'') &= \bc(\rho_{voc(s)}(\EventString{{}|a|{}|b|{}|c|{}}))\\ \notag
				  &= \bc(\EventString{{}|a|{}|b|{}|{}|{}})\\ \notag
				  &= \Before{a}{b} = s
\end{align}
The string $s''$ thus \textit{projects} to the string $s$, which says that the information in $s$ is contained within $s''$. Similarly, the constraint that event $b$ occurs before event $c$ holds in both $s' = \Before{b}{c}$ and in $s''$; $s''$ projects to $s'$.

Since $s''$ projects to both to both $s$ and $s'$, $s''$ also models the constraints that are represented by both $s$ and $s'$, using a single string rather than two strings. However, $s''$ also projects to the string \Before{a}{c}, which represents the constraint that event $a$ occurs before event $c$. This constraint was not represented in either $s$ or $s'$, but is represented in $s''$. Thus, a new relation between events has been discovered and made explicit. 

\subsubsection{Event Ontology}\label{ssub:ontology}
Event hierarchy and using verb/word nets to figure out how events might relate to each other, e.g. using verb roles/participants to forge connections
\subsubsection{Residuals and Gaps}\label{ssub:residuals}
Finding out what additional information would be required on top of some set of premises in order to make some other conclusion(s) true.

\newpage
\section{Implementation}\label{sec:implementation}
Various approaches were trialled using different programming languages, including Prolog, JavaScript (Node.js), and Python. Ultimately, Python was chosen for its speed, wide cross-platform availability, and availability of compatible tooling.

Ultimately a widely-useable package was created that could be used either on the web or as a standalone application, as this gave the broadest opportunity to demonstrate the use of the developed technology.

It combined data and technologies from a number of sources to create a package that could be used to reason about temporal information, and augment annotation-based data in a way that is both efficient and simple-to-use \nb{hard claim to make without a study backing it up...}

\subsection{Back-end Pipeline}\label{sub:backend} % ?NLTK
This is the main stuff. Lots of python code all interacting with the data and PMB and Boxer (and the failure of old boxer and why the output is basically theoretical).

Describe all the moving parts, but mostly go into detail about the different API layers (i.e. multiple languages, tooling exposing only certain parts, NLTK having only some parts up to scratch), and the code that I personally wrote to stitch them all together, since that's basically the only sort-of valuable thing in this entire project.

\subsection{Front-end Interface}\label{sub:frontend}
Brython application with some JS to grease the wheels -- why not TKinter? because HTML and CSS are convenient and widely used tools and allow for a web-based interface as well as an offline tool (electron for packaging? maybe?) why not just use js frontend and python in the backend? python generators are hard, and don't play nice when you want to use `next()' to use an effectively ``pausable" function and get a new value.

\newpage
\section{Evaluation}\label{sec:evaluation}
Evaluation was performed on the basis of three main components: asserting that the results produced were not invalid (i.e. did not cause contradictions internally within a string/language or externally within a knowledge-base), performing inferences using the FRACAS semantic test suite, and verifying that all implementation code was tested so as to produce exactly and only the expected results. \nb{how and why does this add \textit{value} -- data is compressed? human readable/intuitive?}
\subsection{Timeline Validity}\label{sub:validity}
If data is superposed or otherwise manipulated, no information is lost or falsified in the process.
\subsection{FRACAS Semantic Test Suite}\label{sub:fracas}
A de facto standard for testing semantic inferencing.
\subsection{Correctness of Code}\label{sub:correct}
Python test suites.
\newpage
\section{Conclusion}\label{sec:conclusion}
What have I spent the last four and a half years of my life doing?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                              %
%                             Actual Document Ends                             %
%                                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\pagestyle{empty}
\onehalfspacing
\bibliographystyle{apa}
\bibliography{refs}
\newpage
%\appendix
\section*{Appendices}
\addcontentsline{toc}{section}{Appendices}
\subsection*{Python Code}
\addcontentsline{toc}{subsection}{Python Code}
\end{document}